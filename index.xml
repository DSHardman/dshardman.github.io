<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Dr David Hardman</title>
    <link>https://dshardman.github.io/</link>
      <atom:link href="https://dshardman.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Dr David Hardman</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 01 Jun 2030 13:00:00 +0000</lastBuildDate>
    <image>
      <url>https://dshardman.github.io/media/icon_hu9d558420c7118401edbc78d30d177da6_214587_512x512_fill_lanczos_center_3.png</url>
      <title>Dr David Hardman</title>
      <link>https://dshardman.github.io/</link>
    </image>
    
    <item>
      <title>Example Talk</title>
      <link>https://dshardman.github.io/talk/example-talk/</link>
      <pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/talk/example-talk/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Wowchemy&amp;rsquo;s &lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Slides&lt;/em&gt;&lt;/a&gt; feature and link using &lt;code&gt;slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Further event details, including &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;page elements&lt;/a&gt; such as image galleries, can be added to the body of this page.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Design and Modelling of Electrical Impedance Tomography-based 3D-Printed Patterned Soft Tactile Skins</title>
      <link>https://dshardman.github.io/publication/yunqi/</link>
      <pubDate>Mon, 06 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/publication/yunqi/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Henslow Fellowship Election</title>
      <link>https://dshardman.github.io/post/fitzfellow/</link>
      <pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/post/fitzfellow/</guid>
      <description>&lt;p&gt;From October 2024, I&amp;rsquo;ve started a new position as a Henslow Fellow at &lt;a href=&#34;https://www.fitz.cam.ac.uk/person/mr-david-hardman&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Fitzwilliam College, Cambridge&lt;/a&gt;. This is a 3-year Junior Research Fellowship supported by &lt;a href=&#34;https://www.cambridgephilosophicalsociety.org/funding/henslow-fellows/david-hardman&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cambridge Philosophical Society&lt;/a&gt;, a society with a fascinating involvement and history of shaping modern science.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m very excited to dive into this role; I have some very fond memories of the past 8 years at &lt;a href=&#34;https://www.corpus.cam.ac.uk/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Corpus&lt;/a&gt;, but I&amp;rsquo;m now able to mark my transition from student life by becoming just as involved with the Fitz community!&lt;/p&gt;
&lt;blockquote class=&#34;instagram-media&#34; data-instgrm-captioned data-instgrm-permalink=&#34;https://www.instagram.com/p/DC1NkIdoFyO/?utm_source=ig_embed&amp;amp;utm_campaign=loading&#34; data-instgrm-version=&#34;14&#34; style=&#34; background:#FFF; border:0; border-radius:3px; box-shadow:0 0 1px 0 rgba(0,0,0,0.5),0 1px 10px 0 rgba(0,0,0,0.15); margin: 1px; max-width:540px; min-width:326px; padding:0; width:99.375%; width:-webkit-calc(100% - 2px); width:calc(100% - 2px);&#34;&gt;&lt;div style=&#34;padding:16px;&#34;&gt; &lt;a href=&#34;https://www.instagram.com/p/DC1NkIdoFyO/?utm_source=ig_embed&amp;amp;utm_campaign=loading&#34; style=&#34; background:#FFFFFF; line-height:0; padding:0 0; text-align:center; text-decoration:none; width:100%;&#34; target=&#34;_blank&#34;&gt; &lt;div style=&#34; display: flex; flex-direction: row; align-items: center;&#34;&gt; &lt;div style=&#34;background-color: #F4F4F4; border-radius: 50%; flex-grow: 0; height: 40px; margin-right: 14px; width: 40px;&#34;&gt;&lt;/div&gt; &lt;div style=&#34;display: flex; flex-direction: column; flex-grow: 1; justify-content: center;&#34;&gt; &lt;div style=&#34; background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; margin-bottom: 6px; width: 100px;&#34;&gt;&lt;/div&gt; &lt;div style=&#34; background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; width: 60px;&#34;&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div style=&#34;padding: 19% 0;&#34;&gt;&lt;/div&gt; &lt;div style=&#34;display:block; height:50px; margin:0 auto 12px; width:50px;&#34;&gt;&lt;svg width=&#34;50px&#34; height=&#34;50px&#34; viewBox=&#34;0 0 60 60&#34; version=&#34;1.1&#34; xmlns=&#34;https://www.w3.org/2000/svg&#34; xmlns:xlink=&#34;https://www.w3.org/1999/xlink&#34;&gt;&lt;g stroke=&#34;none&#34; stroke-width=&#34;1&#34; fill=&#34;none&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;g transform=&#34;translate(-511.000000, -20.000000)&#34; fill=&#34;#000000&#34;&gt;&lt;g&gt;&lt;path d=&#34;M556.869,30.41 C554.814,30.41 553.148,32.076 553.148,34.131 C553.148,36.186 554.814,37.852 556.869,37.852 C558.924,37.852 560.59,36.186 560.59,34.131 C560.59,32.076 558.924,30.41 556.869,30.41 M541,60.657 C535.114,60.657 530.342,55.887 530.342,50 C530.342,44.114 535.114,39.342 541,39.342 C546.887,39.342 551.658,44.114 551.658,50 C551.658,55.887 546.887,60.657 541,60.657 M541,33.886 C532.1,33.886 524.886,41.1 524.886,50 C524.886,58.899 532.1,66.113 541,66.113 C549.9,66.113 557.115,58.899 557.115,50 C557.115,41.1 549.9,33.886 541,33.886 M565.378,62.101 C565.244,65.022 564.756,66.606 564.346,67.663 C563.803,69.06 563.154,70.057 562.106,71.106 C561.058,72.155 560.06,72.803 558.662,73.347 C557.607,73.757 556.021,74.244 553.102,74.378 C549.944,74.521 548.997,74.552 541,74.552 C533.003,74.552 532.056,74.521 528.898,74.378 C525.979,74.244 524.393,73.757 523.338,73.347 C521.94,72.803 520.942,72.155 519.894,71.106 C518.846,70.057 518.197,69.06 517.654,67.663 C517.244,66.606 516.755,65.022 516.623,62.101 C516.479,58.943 516.448,57.996 516.448,50 C516.448,42.003 516.479,41.056 516.623,37.899 C516.755,34.978 517.244,33.391 517.654,32.338 C518.197,30.938 518.846,29.942 519.894,28.894 C520.942,27.846 521.94,27.196 523.338,26.654 C524.393,26.244 525.979,25.756 528.898,25.623 C532.057,25.479 533.004,25.448 541,25.448 C548.997,25.448 549.943,25.479 553.102,25.623 C556.021,25.756 557.607,26.244 558.662,26.654 C560.06,27.196 561.058,27.846 562.106,28.894 C563.154,29.942 563.803,30.938 564.346,32.338 C564.756,33.391 565.244,34.978 565.378,37.899 C565.522,41.056 565.552,42.003 565.552,50 C565.552,57.996 565.522,58.943 565.378,62.101 M570.82,37.631 C570.674,34.438 570.167,32.258 569.425,30.349 C568.659,28.377 567.633,26.702 565.965,25.035 C564.297,23.368 562.623,22.342 560.652,21.575 C558.743,20.834 556.562,20.326 553.369,20.18 C550.169,20.033 549.148,20 541,20 C532.853,20 531.831,20.033 528.631,20.18 C525.438,20.326 523.257,20.834 521.349,21.575 C519.376,22.342 517.703,23.368 516.035,25.035 C514.368,26.702 513.342,28.377 512.574,30.349 C511.834,32.258 511.326,34.438 511.181,37.631 C511.035,40.831 511,41.851 511,50 C511,58.147 511.035,59.17 511.181,62.369 C511.326,65.562 511.834,67.743 512.574,69.651 C513.342,71.625 514.368,73.296 516.035,74.965 C517.703,76.634 519.376,77.658 521.349,78.425 C523.257,79.167 525.438,79.673 528.631,79.82 C531.831,79.965 532.853,80.001 541,80.001 C549.148,80.001 550.169,79.965 553.369,79.82 C556.562,79.673 558.743,79.167 560.652,78.425 C562.623,77.658 564.297,76.634 565.965,74.965 C567.633,73.296 568.659,71.625 569.425,69.651 C570.167,67.743 570.674,65.562 570.82,62.369 C570.966,59.17 571,58.147 571,50 C571,41.851 570.966,40.831 570.82,37.631&#34;&gt;&lt;/path&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/div&gt;&lt;div style=&#34;padding-top: 8px;&#34;&gt; &lt;div style=&#34; color:#3897f0; font-family:Arial,sans-serif; font-size:14px; font-style:normal; font-weight:550; line-height:18px;&#34;&gt;View this post on Instagram&lt;/div&gt;&lt;/div&gt;&lt;div style=&#34;padding: 12.5% 0;&#34;&gt;&lt;/div&gt; &lt;div style=&#34;display: flex; flex-direction: row; margin-bottom: 14px; align-items: center;&#34;&gt;&lt;div&gt; &lt;div style=&#34;background-color: #F4F4F4; border-radius: 50%; height: 12.5px; width: 12.5px; transform: translateX(0px) translateY(7px);&#34;&gt;&lt;/div&gt; &lt;div style=&#34;background-color: #F4F4F4; height: 12.5px; transform: rotate(-45deg) translateX(3px) translateY(1px); width: 12.5px; flex-grow: 0; margin-right: 14px; margin-left: 2px;&#34;&gt;&lt;/div&gt; &lt;div style=&#34;background-color: #F4F4F4; border-radius: 50%; height: 12.5px; width: 12.5px; transform: translateX(9px) translateY(-18px);&#34;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div style=&#34;margin-left: 8px;&#34;&gt; &lt;div style=&#34; background-color: #F4F4F4; border-radius: 50%; flex-grow: 0; height: 20px; width: 20px;&#34;&gt;&lt;/div&gt; &lt;div style=&#34; width: 0; height: 0; border-top: 2px solid transparent; border-left: 6px solid #f4f4f4; border-bottom: 2px solid transparent; transform: translateX(16px) translateY(-4px) rotate(30deg)&#34;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div style=&#34;margin-left: auto;&#34;&gt; &lt;div style=&#34; width: 0px; border-top: 8px solid #F4F4F4; border-right: 8px solid transparent; transform: translateY(16px);&#34;&gt;&lt;/div&gt; &lt;div style=&#34; background-color: #F4F4F4; flex-grow: 0; height: 12px; width: 16px; transform: translateY(-4px);&#34;&gt;&lt;/div&gt; &lt;div style=&#34; width: 0; height: 0; border-top: 8px solid #F4F4F4; border-left: 8px solid transparent; transform: translateY(-4px) translateX(8px);&#34;&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt; &lt;div style=&#34;display: flex; flex-direction: column; flex-grow: 1; justify-content: center; margin-bottom: 24px;&#34;&gt; &lt;div style=&#34; background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; margin-bottom: 6px; width: 224px;&#34;&gt;&lt;/div&gt; &lt;div style=&#34; background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; width: 144px;&#34;&gt;&lt;/div&gt;&lt;/div&gt;&lt;/a&gt;&lt;p style=&#34; color:#c9c8cd; font-family:Arial,sans-serif; font-size:14px; line-height:17px; margin-bottom:0; margin-top:8px; overflow:hidden; padding:8px 0 7px; text-align:center; text-overflow:ellipsis; white-space:nowrap;&#34;&gt;&lt;a href=&#34;https://www.instagram.com/p/DC1NkIdoFyO/?utm_source=ig_embed&amp;amp;utm_campaign=loading&#34; style=&#34; color:#c9c8cd; font-family:Arial,sans-serif; font-size:14px; font-style:normal; font-weight:normal; line-height:17px; text-decoration:none;&#34; target=&#34;_blank&#34;&gt;A post shared by Fitzwilliam College (@fitzwilliamcoll)&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//www.instagram.com/embed.js&#34;&gt;&lt;/script&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Last night the Governing Body elected three new Fellows to the College - welcome to Dr Natalie Morningstar (who was previously a bye fellow), Mr David Hardman and Ms Rebecca Heath. &lt;a href=&#34;https://t.co/SWtv7G10Ul&#34;&gt;pic.twitter.com/SWtv7G10Ul&lt;/a&gt;&lt;/p&gt;&amp;mdash; Fitzwilliam College (@FitzwilliamColl) &lt;a href=&#34;https://twitter.com/FitzwilliamColl/status/1846974493962518841?ref_src=twsrc%5Etfw&#34;&gt;October 17, 2024&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;</description>
    </item>
    
    <item>
      <title>EPSRC Doctoral Prize</title>
      <link>https://dshardman.github.io/post/epsrc/</link>
      <pubDate>Tue, 01 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/post/epsrc/</guid>
      <description>&lt;p&gt;Based on my PhD work on sensorised skins for soft robots, I&amp;rsquo;ve been awarded a 2024-2025 Doctoral Prize Fellowship from the Engineering and Physical Sciences Research Council (&lt;a href=&#34;https://www.ukri.org/councils/epsrc/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;EPSRC&lt;/a&gt;). According to their website:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&amp;ldquo;The EPSRC Doctoral Prize helps universities retain and recruit the best doctoral students receiving EPSRC support to increase the impact of their doctorate, and to improve retention of the very best students in research careers.&amp;rdquo;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Alongside my JRF, this position gives me a brilliant amount of freedom to pursue my personal research, pushing these technologies and their impact as far as possible.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A summer in Switzerland</title>
      <link>https://dshardman.github.io/post/epfl/</link>
      <pubDate>Mon, 30 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/post/epfl/</guid>
      <description>&lt;p&gt;I was lucky enough to spend the summer as a visiting researcher in Prof. Josie Hughes&amp;rsquo;s CREATE Lab at EPFL, Lausanne. My reflections are described in the LinkedIn post below - this was a very memorable experience!&lt;/p&gt;
&lt;iframe src=&#34;https://www.linkedin.com/embed/feed/update/urn:li:share:7244750337474007041&#34; height=&#34;739&#34; width=&#34;504&#34; frameborder=&#34;0&#34; allowfullscreen=&#34;&#34; title=&#34;Embedded post&#34;&gt;&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>STEM for BRITAIN Finalist</title>
      <link>https://dshardman.github.io/post/stemforbritain/</link>
      <pubDate>Tue, 19 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/post/stemforbritain/</guid>
      <description>&lt;p&gt;On Monday 4th March I presented my work at the STEM for BRITAIN final in the Houses of Parliament. See my poster via &lt;a href=&#34;https://dshardman.github.io/uploads/STEMForBritain.pdf&#34; target=&#34;_blank&#34;&gt;this link&lt;/a&gt;, or find out more about the event &lt;a href=&#34;https://stemforbritain.org.uk/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/SaX3ktDTWP0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Braille-reading robot features on Cambridge University&#39;s website</title>
      <link>https://dshardman.github.io/post/braille-press/</link>
      <pubDate>Mon, 29 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/post/braille-press/</guid>
      <description>&lt;p&gt;Our new paper &amp;ldquo;High-Speed Tactile Braille Reading via Biomimetic Sliding Interactions&amp;rdquo; is featured on Cambridge University&amp;rsquo;s research news following its publication in &lt;em&gt;IEEE Robotics and Automation Letters&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;This work looks at the ways we can use vision-based tactile sensors to interact continuously with the world around us. Braille is an excellent testing ground: whilst it is possible to read each letter one-by-one, it&amp;rsquo;s much quicker to use a continuous sliding motion like humans do!&lt;/p&gt;
&lt;p&gt;Read more &lt;a href=&#34;https://www.cam.ac.uk/research/news/robot-trained-to-read-braille-at-twice-the-speed-of-humans&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;iframe
    width=&#34;640&#34;
    height=&#34;480&#34;
    src=&#34;https://www.youtube.com/embed/xqtA2Z668Ic&#34;
    frameborder=&#34;0&#34;
    allow=&#34;autoplay; encrypted-media&#34;
    allowfullscreen
&gt;
&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>Controllable Wound Closure in Artificial Skins using Dual-Layer Bioinspired Mechanism</title>
      <link>https://dshardman.github.io/publication/langerlines/</link>
      <pubDate>Thu, 18 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/publication/langerlines/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multi-touch Recognition of Hydrogel-based E-skins using Real-world EIT Datasets</title>
      <link>https://dshardman.github.io/publication/lorcan/</link>
      <pubDate>Thu, 18 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/publication/lorcan/</guid>
      <description></description>
    </item>
    
    <item>
      <title>High-Speed Tactile Braille Reading via Biomimetic Sliding Interactions</title>
      <link>https://dshardman.github.io/publication/parth/</link>
      <pubDate>Fri, 05 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/publication/parth/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Variable sensitivity multimaterial robotic e-skin combining electronic and ionic conductivity using electrical impedance tomography</title>
      <link>https://dshardman.github.io/publication/aleix/</link>
      <pubDate>Wed, 15 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/publication/aleix/</guid>
      <description></description>
    </item>
    
    <item>
      <title>How to Fool Your Robot - Designing Exploitable Sensory Systems</title>
      <link>https://dshardman.github.io/publication/fooling/</link>
      <pubDate>Fri, 10 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/publication/fooling/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Autonomous Testing of the Repeatable Healability of Pneumatic Self-Healing Soft Actuators</title>
      <link>https://dshardman.github.io/publication/julie/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/publication/julie/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Sensorized Skin with Biomimetic Tactility Features based on Artificial Crosstalk of Bimodal Resistive Sensory Inputs</title>
      <link>https://dshardman.github.io/publication/advancedscience/</link>
      <pubDate>Thu, 07 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/publication/advancedscience/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Closed-loop Optimization of Soft Sensor Morphology by Using 3-D Printing of Electrically Conductive Hydrogel</title>
      <link>https://dshardman.github.io/publication/sojiro/</link>
      <pubDate>Fri, 01 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/publication/sojiro/</guid>
      <description></description>
    </item>
    
    <item>
      <title>CSAR 2023 Award</title>
      <link>https://dshardman.github.io/post/csar/</link>
      <pubDate>Sun, 25 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/post/csar/</guid>
      <description>&lt;p&gt;&lt;strong&gt;June 2024 update:&lt;/strong&gt; On 10th June 2024 I gave a presentation of my work at a meeting of the society. A recording of this talk can be found at the bottom of this page.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Original post:&lt;/strong&gt;
In a ceremony on 19th June I was one of twelve recipients of the CSAR 2023 PhD student award, awarded &lt;em&gt;&amp;ldquo;in recognition of outstanding research and potential with real world application&amp;rdquo;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;My work was selected from more than 160 applications by the Cambridge Society for the Application of Research. More information and the list of 2023 winners can be found &lt;a href=&#34;https://www.csar.org.uk/student-awards/2023/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;on the CSAR website&lt;/a&gt;.&lt;/p&gt;
&lt;iframe
	width=&#34;1038&#34;
	height=&#34;584&#34;
	src=&#34;https://www.youtube.com/embed/mWAtrvey5js&#34;
	frameborder=&#34;0&#34;
	allow=&#34;autoplay; encrypted-media&#34;
	allowfullscreen
&gt;
&lt;/iframe&gt;</description>
    </item>
    
    <item>
      <title>Composite Stretchable Sensors for the Detection of Asymmetric Deformations in a Soft Manipulator</title>
      <link>https://dshardman.github.io/publication/ringactuator/</link>
      <pubDate>Mon, 15 May 2023 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/publication/ringactuator/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Variable Response Characteristics of a Soft Sensorized Hydrogel using Mesoscale Cellular Structures</title>
      <link>https://dshardman.github.io/publication/naoki/</link>
      <pubDate>Mon, 15 May 2023 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/publication/naoki/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Talks at RoboSoft</title>
      <link>https://dshardman.github.io/post/robosoft23/</link>
      <pubDate>Sat, 15 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/post/robosoft23/</guid>
      <description>&lt;p&gt;During the packed and exciting schedule of the 6th IEEE-RAS International Conference on Soft Robotics (RoboSoft 2023), I was invited to give 2 talks and present one poster (even featuring on the conference&amp;rsquo;s twitter feed!).&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Hats off to you, Hardman! Your presentation on Composite Stretchable Sensors for the Detection of Asymmetric Deformations in a Soft Manipulator was absolutely mind-blowing! &lt;a href=&#34;https://twitter.com/hashtag/RoboSoft2023?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#RoboSoft2023&lt;/a&gt; &lt;a href=&#34;https://t.co/pA5PQShuIZ&#34;&gt;pic.twitter.com/pA5PQShuIZ&lt;/a&gt;&lt;/p&gt;&amp;mdash; IEEERoboSoft (@IEEERoboSoft) &lt;a href=&#34;https://twitter.com/IEEERoboSoft/status/1643460895367110656?ref_src=twsrc%5Etfw&#34;&gt;April 5, 2023&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;Details of all can be found below.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&amp;ldquo;Learning-Based Sensing for Soft Applications.&amp;rdquo;&lt;/strong&gt; An invited 20-minute talk in the &lt;em&gt;Modelling Challenges for Soft Robots&lt;/em&gt; workshop.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&amp;ldquo;Composite Stretchable Sensors for the Detection of Asymmetric Deformations in a Soft Manipulator.&amp;rdquo;&lt;/strong&gt; A 15-minute talk accompanying a paper of the same name being published in the conference proceedings.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&amp;ldquo;Material-level Sensorization of Hydrogel-based Skins using Data-Driven EIT.&amp;rdquo;&lt;/strong&gt; A poster within the &lt;em&gt;Embodied Intelligence and Soft Robotics&lt;/em&gt; workshop, alongside a flash talk of its content.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&amp;ldquo;Variable Response Characteristics of a Soft Sensorized Hydrogel using
Mesoscale Cellular Structures.&amp;rdquo;&lt;/strong&gt; A poster of a paper which I co-authored in the conference proceedings, presented by first author Naoki Tano.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Tactile Perception in Hydrogel-based Robotic Skins using Data-Driven Electrical Impedance Tomography</title>
      <link>https://dshardman.github.io/publication/eitskin/</link>
      <pubDate>Thu, 30 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/publication/eitskin/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Upcoming Research Talk</title>
      <link>https://dshardman.github.io/post/john-ray/</link>
      <pubDate>Mon, 20 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/post/john-ray/</guid>
      <description>&lt;p&gt;From 6-7pm on Tuesday 28th February I&amp;rsquo;ll be presenting the Bio-Inspired Robotics Lab&amp;rsquo;s current research at the &lt;a href=&#34;https://www.johnray.caths.cam.ac.uk/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;John Ray Society&lt;/a&gt; of St Catherine&amp;rsquo;s College Cambridge. Talk details can be found below.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Aiming for All-Purpose Robotics&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Though we have seen many robots and machines optimised to perform a specific task or solve a specific problem, the design of multipurpose robots continues to challenge us. In this talk, David Hardman (Cambridge Bio-Inspired Robotics Lab) introduces the key problems, illustrated with practical examples from his work on biomimetic e-skins.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Design and Development of a Hydrogel-based Soft Sensor for Multi-Axis Force Control</title>
      <link>https://dshardman.github.io/publication/yichen/</link>
      <pubDate>Tue, 17 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/publication/yichen/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning-Based Damage Recovery for Healable Soft Electronic Skins</title>
      <link>https://dshardman.github.io/publication/healingrecovery/</link>
      <pubDate>Mon, 31 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/publication/healingrecovery/</guid>
      <description></description>
    </item>
    
    <item>
      <title>3D Printable Soft Sensory Fiber Networks for Robust and Complex Tactile Sensing</title>
      <link>https://dshardman.github.io/publication/micromachines/</link>
      <pubDate>Sat, 17 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/publication/micromachines/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Robot Talk podcast appearance</title>
      <link>https://dshardman.github.io/post/robot-talk/</link>
      <pubDate>Mon, 13 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/post/robot-talk/</guid>
      <description>&lt;p&gt;Episode 17 of UK-RAS&amp;rsquo;s &lt;em&gt;Robot Talk&lt;/em&gt; podcast has just been released, in which I talk with Dr Claire Asher about the pros and cons of integrating our sensorised hydrogel skins into bio-inspired robots. The episode also features the fascinating work of Valentina Lo Gatto and Adrian Thomas.&lt;/p&gt;
&lt;p&gt;Listen &lt;a href=&#34;https://ukrobotics.libsyn.com/episode-seventeen-bioinspired-robots-learning-from-nature&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&amp;ldquo;&lt;strong&gt;Bioinspired Robots: learning from nature:&lt;/strong&gt;
&lt;em&gt;In many areas of robotics, scientists and engineers are taking inspiration from nature in their designs. Bioinspired robotics now encompasses a huge number of different research fields and applications that we’ve discussed before, from sensing to locomotion and from medical to agricultural robotics. This month, I’m chatting to three roboticists who’ve taken a leaf out of nature’s book to develop innovative new robots.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Valentina Lo Gatto is a PhD student in Robotics and Autonomous Systems at the Bristol Robotics Lab, where she is part of the SoftLab and the Morphological Computation Group. The main goal of her research at BRL is to investigate the application of the concepts of Bioinspiration, Soft Robotics and Morphological Computation to space probes design, specifically probes that will need to be able to autonomously explore delicate marine environments such those hidden under the icy surfaces of some of the moons of the outer solar system (e.g., Europa, Enceladus, Ganymede).&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;David Hardman is a PhD student in the Bio-Inspired Robotics Lab at the University of Cambridge, where he works on the design and development of soft, flexible sensors and sensing materials. After receiving his MEng in mechanical and materials engineering from Cambridge in 2020, he began focussing on including stretchy, bendy, and compliant sensors into robotic systems, where they function as artificial skins which conform to and sense a robot’s surroundings.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Adrian Thomas is Professor of Biomechanics in the Zoology Department, Oxford University. He founded the Oxford Animal Flight Group in 1996, and led that group until 2015 when he founded his Oxford Spinout company Animal Dynamics. Animal Dynamics works on bio inspired autonomous vehicles and systems, mainly cargo delivery in air or underwater. Animal Dynamics has raised over £20 million from venture capital. Its main product is a large cargo delivery drone &amp;lsquo;Stork&amp;rsquo; capable of carrying 135kg over 400km.&amp;rdquo;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Research features on Cambridge University&#39;s news website</title>
      <link>https://dshardman.github.io/post/jelly-press/</link>
      <pubDate>Fri, 18 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/post/jelly-press/</guid>
      <description>&lt;p&gt;My new paper &amp;ldquo;Self-healing ionic gelatin/glycerol hydrogels for strain sensing applications&amp;rdquo; is featured on Cambridge University&amp;rsquo;s research news following its publication in &lt;em&gt;NPG Asia Materials&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;This work looks at the development, characterisation, and applications of a healable gelatin-based sensor for soft robotics. As seen in the University&amp;rsquo;s promotional video below, it is easy to 3D print or cast into different shapes.&lt;/p&gt;
&lt;p&gt;Read more &lt;a href=&#34;https://www.cam.ac.uk/research/news/self-healing-materials-for-robotics-made-from-jelly-and-salt&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;iframe
    width=&#34;640&#34;
    height=&#34;480&#34;
    src=&#34;https://www.youtube.com/embed/eVH0YCeI464&#34;
    frameborder=&#34;0&#34;
    allow=&#34;autoplay; encrypted-media&#34;
    allowfullscreen
&gt;
&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>Self-healing ionic gelatin/glycerol hydrogels for strain sensing applications</title>
      <link>https://dshardman.github.io/publication/npghydrogel/</link>
      <pubDate>Fri, 18 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/publication/npghydrogel/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Research features on department&#39;s website</title>
      <link>https://dshardman.github.io/post/water-press/</link>
      <pubDate>Fri, 28 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/post/water-press/</guid>
      <description>&lt;p&gt;My recent publication in &lt;em&gt;Scientific Reports&lt;/em&gt; - &amp;ldquo;Manipulation of Free-Floating Objects using Faraday Flows and Deep Reinforcement Learning&amp;rdquo; - has just been featured on Cambridge University Engineering Department&amp;rsquo;s website.&lt;/p&gt;
&lt;p&gt;Here I looked at how we can control the motion of an object floating on the surface of water &lt;em&gt;without touching it&lt;/em&gt; - instead just vibrating the water to produce waves at a fixed point nearby. Given the difficulty of modelling this problem, we used deep reinforcement learning trained with real-world data to develop the controller.&lt;/p&gt;
&lt;p&gt;Read more &lt;a href=&#34;http://www.eng.cam.ac.uk/news/remote-control-floating-objects-solving-complex-fluid-dynamics-problem-ai&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;, or see the video below.&lt;/p&gt;
&lt;iframe
    width=&#34;640&#34;
    height=&#34;480&#34;
    src=&#34;https://www.youtube.com/embed/2FzWJyX9ieU&#34;
    frameborder=&#34;0&#34;
    allow=&#34;autoplay; encrypted-media&#34;
    allowfullscreen
&gt;
&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>Manipulation of free-floating objects using Faraday flows and deep reinforcement learning</title>
      <link>https://dshardman.github.io/publication/scientificreports/</link>
      <pubDate>Mon, 10 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/publication/scientificreports/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BIRL joins Robot Lab Live</title>
      <link>https://dshardman.github.io/post/robot-lab-live/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/post/robot-lab-live/</guid>
      <description>&lt;p&gt;&lt;strong&gt;June 2022 update:&lt;/strong&gt; &lt;em&gt;We&amp;rsquo;ll be taking part in this event again this year - see the trailer &lt;a href=&#34;https://www.youtube.com/watch?v=nL2uH8tEKxY&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;On Wednesday 23rd June 4pm-6pm BST, I&amp;rsquo;ll be hosting the Bio-Inspired Robotics Lab&amp;rsquo;s livestreamed demos as part of &lt;a href=&#34;https://www.ukras.org.uk/robotics-week/robot-lab-live/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Robot Lab Live&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ll be exploring how robots can be taught to help doctors examine patients, and how a robotic chef can use taste sensors to improve its scrambled eggs. After presenting our research we&amp;rsquo;ll be asking the live audience: &lt;em&gt;&amp;ldquo;Would you eat breakfast that&amp;rsquo;s been cooked by a robot?&amp;rdquo;&lt;/em&gt;&lt;/p&gt;
&lt;iframe
    width=&#34;640&#34;
    height=&#34;480&#34;
    src=&#34;https://www.youtube.com/embed/MwhnJaQqEz4&#34;
    frameborder=&#34;0&#34;
    allow=&#34;autoplay; encrypted-media&#34;
    allowfullscreen
&gt;
&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>3D Printable Sensorized Soft Gelatin Hydrogel for Multi-Material Soft Structures</title>
      <link>https://dshardman.github.io/publication/ral-hydrogel/</link>
      <pubDate>Sun, 18 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/publication/ral-hydrogel/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Towards Growing Robots - A Piecewise Morphology-Controller Co-adaptation Strategy for Legged Locomotion</title>
      <link>https://dshardman.github.io/publication/taros/</link>
      <pubDate>Thu, 03 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/publication/taros/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://dshardman.github.io/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://owchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://revealjs.com/pdf-export/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;porridge&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;blueberry&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;porridge&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;blueberry&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Eating...&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% fragment %}} One {{% /fragment %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% fragment %}} **Two** {{% /fragment %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% fragment %}} Three {{% /fragment %}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;span class=&#34;fragment &#34; &gt;
  One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
  &lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
  Three
&lt;/span&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% speaker_note %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;-&lt;/span&gt; Only the speaker can read these notes
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;-&lt;/span&gt; Press &lt;span class=&#34;sb&#34;&gt;`S`&lt;/span&gt; key to view
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  {{% /speaker_note %}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;background-image&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;/media/boards.jpg&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;background-color&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;#0000FF&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;class&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;my-style&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-css&#34; data-lang=&#34;css&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h3&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;color&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;navy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/discussions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example Project</title>
      <link>https://dshardman.github.io/project/example/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/project/example/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://dshardman.github.io/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/admin/config.yml</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
