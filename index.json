
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"I’m a third year PhD student at the Bio-Inspired Robotics Laboratory, under the supervision of Professor Fumiya Iida. I work on the implementation of unconventional soft materials in robotic systems, with a particular interest in medical applications. I’m also a member of the SHERO project for self-healing soft robotics.\nIn my free time I like to play badminton and tennis, and I’m a member of the world-famous Magic Circle.\nDownload my CV.\n","date":1661990400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1661990400,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I’m a third year PhD student at the Bio-Inspired Robotics Laboratory, under the supervision of Professor Fumiya Iida. I work on the implementation of unconventional soft materials in robotic systems, with a particular interest in medical applications.","tags":null,"title":"David Hardman","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://dshardman.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Seppe Terryn","David Hardman","Thomas George Thuruthel","Ellen Roels","Fatemeh Sahraeeazartamar","Fumiya Iida"],"categories":null,"content":"","date":1661990400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661990400,"objectID":"91eb151558057bf789a1da3799f9cce2","permalink":"https://dshardman.github.io/publication/healingrecovery/","publishdate":"2022-09-01T00:00:00Z","relpermalink":"/publication/healingrecovery/","section":"publication","summary":"Comparing recalibration methods for a sensorised skin which has damaged and healed in multiple locations, affecting the response of the sensor channels. Transfer learning is used to recover the tactile sensitivity as quickly as possible.","tags":[],"title":"Learning-Based Damage Recovery for Healable Soft Electronic Skins","type":"publication"},{"authors":["David Hardman"],"categories":"","content":"Markdown content goes here\n","date":1655078400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655078400,"objectID":"1c13e0e5d19df9f3f6c46ce5c387ce2c","permalink":"https://dshardman.github.io/post/robot-talk/","publishdate":"2022-06-13T00:00:00Z","relpermalink":"/post/robot-talk/","section":"post","summary":"I talk to Dr Claire Asher in Episode 17 of Robot Talk - Bioinspired Robots: learning from nature.","tags":"","title":"Robot Talk Podcast Appearance","type":"post"},{"authors":["David Hardman","Thomas George Thuruthel","Fumiya Iida"],"categories":null,"content":"","date":1645142400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645142400,"objectID":"147b951c8c109d9f04c216fbe334ca01","permalink":"https://dshardman.github.io/publication/npghydrogel/","publishdate":"2022-02-18T00:00:00Z","relpermalink":"/publication/npghydrogel/","section":"publication","summary":"Development, characterisation, and applications of a healable gelatin-based sensor for soft robotics.","tags":[],"title":"Self-healing ionic gelatin/glycerol hydrogels for strain sensing applications","type":"publication"},{"authors":["David Hardman"],"categories":"","content":"Markdown content goes here\nLink here.\n","date":1643328000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643328000,"objectID":"fdce7bd311d926c8b5de48408dcad4b7","permalink":"https://dshardman.github.io/post/water-press/","publishdate":"2022-01-28T00:00:00Z","relpermalink":"/post/water-press/","section":"post","summary":"My recent paper \"Manipulation of free-floating objects using Faraday flows and deep reinforcement learning\" has been featured on Cambridge University's Engineering Department website.","tags":"","title":"Research features on department website","type":"post"},{"authors":["David Hardman","Thomas George Thuruthel","Fumiya Iida"],"categories":null,"content":"","date":1641772800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641772800,"objectID":"946043fda4c023f62b843aebd2d74585","permalink":"https://dshardman.github.io/publication/scientificreports/","publishdate":"2022-01-10T00:00:00Z","relpermalink":"/publication/scientificreports/","section":"publication","summary":"The ability to remotely control a free-floating object through surface flows on a fluid medium can facilitate numerous applications. Current studies on this problem have been limited to uni-directional motion control due to the challenging nature of the control problem. Analytical modelling of the object dynamics is difficult due to the high-dimensionality and mixing of the surface flows while the control problem is hard due to the nonlinear slow dynamics of the fluid medium, underactuation, and chaotic regions. This study presents a methodology for manipulation of free-floating objects using large-scale physical experimentation and recent advances in deep reinforcement learning. We demonstrate our methodology through the open-loop control of a free-floating object in water using a robotic arm. Our learned control policy is relatively quick to obtain, highly data efficient, and easily scalable to a higher-dimensional parameter space and/or experimental scenarios. Our results show the potential of data-driven approaches for solving and analyzing highly complex nonlinear control problems.","tags":[],"title":"Manipulation of free-floating objects using Faraday flows and deep reinforcement learning","type":"publication"},{"authors":["David Hardman"],"categories":"","content":"June 2022 update: We’ll be taking part in this event again this year - see the trailer here.\nOn Wednesday 23rd June 4pm-6pm BST, I’ll be hosting the Bio-Inspired Robotics Lab’s livestreamed demos as part of Robot Lab Live.\nWe’ll be exploring how robots can be taught to help doctors examine patients, and how a robotic chef can use taste sensors to improve its scrambled eggs. After presenting our research we’ll be asking the live audience: “Would you eat breakfast that’s been cooked by a robot?”\n","date":1622505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622505600,"objectID":"743b3dade39b362b16dd626d5c7cc619","permalink":"https://dshardman.github.io/post/robot-lab-live/","publishdate":"2021-06-01T00:00:00Z","relpermalink":"/post/robot-lab-live/","section":"post","summary":"I'll be hosting the lab's livestreamed demos at EPSRC UK-Robotics and Autonomous Systems (UK-RAS) Network's flagship event.","tags":"","title":"BIRL joins Robot Lab Live","type":"post"},{"authors":["David Hardman","Josie Hughes","Thomas George Thuruthel","Kieran Gilday","Fumiya Iida"],"categories":null,"content":"","date":1618704000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618704000,"objectID":"5b6f886a238d28ee0c42ae96847add3e","permalink":"https://dshardman.github.io/publication/ral-hydrogel/","publishdate":"2021-04-18T00:00:00Z","relpermalink":"/publication/ral-hydrogel/","section":"publication","summary":"The ability to 3D print soft materials with integrated strain sensors enables significant flexibility for the design and fabrication of soft robots. Hydrogels provide an interesting alternative to traditional soft robot materials, allowing for more varied fabrication techniques. In this work, we investigate the 3D printing of a gelatin-glycerol hydrogel, where transglutaminase is used to catalyse the crosslinking of the hydrogel such that its material properties can be controlled for 3D printing. By including electron-conductive elements (aqueous carbon black) in the hydrogel we can create highly flexible and linear soft strain sensors. We present a first investigation into adapting a desktop 3D printer and optimizing its control parameters to fabricate sensorized 2D and 3D structures which can undergo \u003e300% strain and show a response to strain which is highly linear and synchronous. To demonstrate the capabilities of this material and fabrication approach, we produce some example 2D and 3D structres and show their sensing capabilities.","tags":[],"title":"3D Printable Sensorized Soft Gelatin Hydrogel for Multi-Material Soft Structures","type":"publication"},{"authors":["David Hardman","Thomas George Thuruthel","Fumiya Iida"],"categories":null,"content":"","date":1606953600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606953600,"objectID":"7d23d6f02d1e4daec1b314b8c53cf0c0","permalink":"https://dshardman.github.io/publication/taros/","publishdate":"2020-12-03T00:00:00Z","relpermalink":"/publication/taros/","section":"publication","summary":"Control of robots has largely been based on the assumption of a fixed morphology. Accordingly, robot designs have been stationary in time, except for the case of modular robots. Any drastic change in morphology, hence, requires a remodelling of the controller. This work takes inspiration from developmental robotics to present a piecewise morphology-controller growth/adaptation strategy that facilitates fast and reliable control adaptation to growing robots. We demonstrate our methodology on a simple 3 degree of freedom walking robot with adjustable foot lengths and with varying inertial conditions. Our results show not only the effectiveness and reliability of the piecewise morphology controller co-adaptation (PMCCA) strategy, but also highlight the need for morphological adaptation as a robot design strategy.","tags":[],"title":"Towards Growing Robots - A Piecewise Morphology-Controller Co-adaptation Strategy for Legged Locomotion","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://dshardman.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"https://dshardman.github.io/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"}]