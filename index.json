
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"I’m in my final year of a PhD at Cambridge’s Bio-Inspired Robotics Laboratory, building tactile sensors and artificial skins. I was part of the Horizon 2020 SHERO project for self-healing robotics, and the Samsung Global Research Outreach project on tactile perception.\nIn my spare time I enjoy playing badminton and tennis, and I’m a member of the world-famous Magic Circle.\nDownload my CV.\n","date":1708300800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1708300800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I’m in my final year of a PhD at Cambridge’s Bio-Inspired Robotics Laboratory, building tactile sensors and artificial skins. I was part of the Horizon 2020 SHERO project for self-healing robotics, and the Samsung Global Research Outreach project on tactile perception.","tags":null,"title":"David Hardman","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://dshardman.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["David Hardman"],"categories":"","content":" See my poster here.\n","date":1708300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1708300800,"objectID":"f1c9698b80070074394703584ded7bf2","permalink":"https://dshardman.github.io/post/stemforbritain/","publishdate":"2024-02-19T00:00:00Z","relpermalink":"/post/stemforbritain/","section":"post","summary":"I'll be presenting my work at the STEM for BRITAIN final in the Houses of Parliament on Monday 4th March.","tags":"","title":"STEM for BRITAIN Finalist","type":"post"},{"authors":["David Hardman"],"categories":"","content":"Our new paper “High-Speed Tactile Braille Reading via Biomimetic Sliding Interactions” is featured on Cambridge University’s research news following its publication in IEEE Robotics and Automation Letters.\nThis work looks at the ways we can use vision-based tactile sensors to interact continuously with the world around us. Braille is an excellent testing ground: whilst it is possible to read each letter one-by-one, it’s much quicker to use a continuous sliding motion like humans do!\nRead more here.\n","date":1706486400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706486400,"objectID":"e988eec56902d69389145e5b63db7a0c","permalink":"https://dshardman.github.io/post/braille-press/","publishdate":"2024-01-29T00:00:00Z","relpermalink":"/post/braille-press/","section":"post","summary":"Our recent paper \"High-Speed Tactile Braille Reading via Biomimetic Sliding Interactions\" is promoted by Cambridge University after its publication in IEEE Robotics and Automation Letters.","tags":"","title":"Braille-reading robot features on Cambridge University's website","type":"post"},{"authors":["David Hardman","Fumiya Iida"],"categories":null,"content":"","date":1705536000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1705536000,"objectID":"9d7dcb212e20fed4e5bcd2aee56493d2","permalink":"https://dshardman.github.io/publication/langerlines/","publishdate":"2024-01-18T00:00:00Z","relpermalink":"/publication/langerlines/","section":"publication","summary":"Punctures and surface damage can be catastrophic for soft robotic systems. Inspired by the self-sealing deformations of plants and the anisotropic distribution of collagen in the human skin's dermis, we present a dual-layer skin with controllable wound closure. Anisotropic elastomer channels are used to tune the directionality of the skin's mechanical stiffness, whilst an outermost hydrogel layer grows and shrinks as humidity is varied, generating stresses which close and open the wounds. We demonstrate and characterize the core principles of both mechanisms, before exploring the effects of composite parameters and morphologies. Repeatable and precise damage is inflicted using a CNC scalpel blade. Finally, we demonstrate the use of these mechanisms to seal scalpel cuts on an artificial hand, immediately restoring electrical channels broken by the wound.","tags":[],"title":"Controllable Wound Closure in Artificial Skins using Dual-Layer Bioinspired Mechanism","type":"publication"},{"authors":["Lorcan Nicholls","David Hardman","Fumiya Iida"],"categories":null,"content":"","date":1705536000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1705536000,"objectID":"c8285fb2cc7e5bc45694fd8f4adbd653","permalink":"https://dshardman.github.io/publication/lorcan/","publishdate":"2024-01-18T00:00:00Z","relpermalink":"/publication/lorcan/","section":"publication","summary":"We present a soft gelatin-based hydrogel e-skin capable of detecting up to six simultaneous tactile stimuli, using electrical impedance tomography (EIT) measurements and convolutional neural networks. Our networks are trained on only real-world data, for which we present two custom data-collecting end-effectors. These allow multi-touch responses to be measured quickly and autonomously (up to 8 seconds per datapoint), giving datasets more than 10x larger than those existing in the literature. To demonstrate the benefits of this approach, we train a non-homogeneous skin to predict `macro-braille' patterns in a 3x2 grid, achieving a 89\\% classification accuracy.","tags":[],"title":"Multi-touch Recognition of Hydrogel-based E-skins using Real-world EIT Datasets","type":"publication"},{"authors":["Parth Potdar","David Hardman","Elijah Almanzor","Fumiya Iida"],"categories":null,"content":"","date":1704412800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704412800,"objectID":"6483189eb20796fca9fddcfcdf28e2a1","permalink":"https://dshardman.github.io/publication/parth/","publishdate":"2024-01-05T00:00:00Z","relpermalink":"/publication/parth/","section":"publication","summary":"Most braille-reading robotic sensors employ a discrete letter-by-letter reading strategy, despite the higher potential speeds of a biomimetic sliding approach. We propose a complete pipeline for continuous braille reading - frames are dynamically collected with a vision-based tactile sensor; an autoencoder removes motion-blurring artefacts; a lightweight YOLO v8 model classifies the braille characters; and a data-driven consolidation stage minimizes errors in the predicted string. We demonstrate a state-of-the-art speed of 315 words per minute at 87.5\\% accuracy, more than twice the speed of human braille reading. Whilst demonstrated on braille, this biomimetic sliding approach can be further employed for richer dynamic spatial and temporal detection of surface textures, and we consider the challenges which must be addressed in its development.","tags":[],"title":"High-Speed Tactile Braille Reading via Biomimetic Sliding Interactions","type":"publication"},{"authors":["Aleix Costa Cornellà","David Hardman","Leone Costi","Joost Brancart","Guy Van Assche","Fumiya Iida"],"categories":null,"content":"","date":1700006400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1700006400,"objectID":"45cdfae7d11d225e083fbfed4ca4e6e5","permalink":"https://dshardman.github.io/publication/aleix/","publishdate":"2023-11-15T00:00:00Z","relpermalink":"/publication/aleix/","section":"publication","summary":"Electronic skins (e-skins) aim to replicate the capabilities of human skin by integrating electronic components and advanced materials into a flexible, thin, and stretchable substrate. Electrical impedance tomography (EIT) has recently been adopted in the area of e-skin thanks to its robustness and simplicity of fabrication compared to previous methods. However, the most common EIT configurations have limitations in terms of low sensitivities in areas far from the electrodes. Here we combine two piezoresistive materials with different conductivities and charge carriers, creating anisotropy in the sensitive part of the e-skin. The bottom layer consists of an ionically conducting hydrogel, while the top layer is a self-healing composite that conducts electrons through a percolating carbon black network. By changing the pattern of the top layer, the resulting distribution of currents in the e-skin can be tuned to locally adapt the sensitivity. This approach can be used to biomimetically adjust the sensitivities of different regions of the skin. It was demonstrated how the sensitivity increased by 500% and the localization error reduced by 40% compared to the homogeneous case, eliminating the lower sensitivity regions. This principle enables integrating the various sensing capabilities of our skins into complex 3D geometries. In addition, both layers of the developed e-skin have self-healing capabilities, showing no statistically significant difference in localization performance before the damage and after healing. The self-healing bilayer e-skin could recover full sensing capabilities after healing of severe damage.","tags":[],"title":"Variable sensitivity multimaterial robotic e-skin combining electronic and ionic conductivity using electrical impedance tomography","type":"publication"},{"authors":["David Hardman","Fumiya Iida"],"categories":null,"content":"","date":1699574400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1699574400,"objectID":"a5d198130e5b4b045fdcc879bfb6909f","permalink":"https://dshardman.github.io/publication/fooling/","publishdate":"2023-11-10T00:00:00Z","relpermalink":"/publication/fooling/","section":"publication","summary":"Based on real-world interactions in our lives and in the lives of our ancestors, humans have developed a multitude of psychological, social, and reflexive actions for efficient living. We consider the integration of similar behaviours into embodied robots through the design of their sensory systems, evaluating their impact through a novel lens - how magicians exploit these human behaviours in order to fool their spectators into experiencing impossible events. We explore the consequences of designing agents which can experience magic effects, and argue that such design facilities lifelike actions.","tags":[],"title":"How to Fool Your Robot - Designing Exploitable Sensory Systems","type":"publication"},{"authors":["Julie Legrand","Arsen Abdulali","David Hardman","Seppe Terryn","Bram Vanderborght","Fumiya Iida"],"categories":null,"content":"","date":1695600000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695600000,"objectID":"4557ae0b59bc5e62f9dcdf3f686b4764","permalink":"https://dshardman.github.io/publication/julie/","publishdate":"2023-09-25T00:00:00Z","relpermalink":"/publication/julie/","section":"publication","summary":"The maximum number of damage and healing cycles which can be endured by a self-healing actuator, i.e. its repeatable healability, has never been assessed. One reason for this is because healability was always tested manually. Typically, an operator uses a sharp blade to manually damage the actuator and places both damaged edges back together for them to heal. This process is time-consuming, which explains why only a limited amount of damage and healing cycles have been reported. Moreover, this leads to an inaccurate estimation of how repeatable the actuator’s healability is, since manual damage cannot be always performed at the exact same location. Therefore, we present a method to automatically and autonomously assess the repeatable healability of a soft self-healing actuator. It uses a robotic system composed of a damage station and a healing station, which the actuator is automatically moved between using a robotic arm. A sensor integrated inside the actuator is used alongside a dedicated characterisation algorithm to automatically indicate whether the actuator is properly damaged and healed. We present a typical use case of the system, performing and analyzing 63 damage cycles of a self-healing Diels-Alder actuator. After 53 cycles, the actuator will never properly heal again, therefore, we consider this cycle to be the maximum repeatable healability of the tested actuator. The healability of the self-healing Diels-Alder actuator is therefore not infinite experimentally.","tags":[],"title":"Autonomous Testing of the Repeatable Healability of Pneumatic Self-Healing Soft Actuators","type":"publication"},{"authors":["Antonia Georgopoulou","David Hardman","Thomas George Thuruthel","Fumiya Iida","Frank Clemens"],"categories":null,"content":"","date":1694044800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1694044800,"objectID":"14839a1e27502397f48d33b815f30954","permalink":"https://dshardman.github.io/publication/advancedscience/","publishdate":"2023-09-07T00:00:00Z","relpermalink":"/publication/advancedscience/","section":"publication","summary":"Mimicking the structure of the human skin by combining surface level thermoreceptors with deeper mechanoreceptors. Tactile stimuli are identified using a feedforward neural network.","tags":[],"title":"Sensorized Skin with Biomimetic Tactility Features based on Artificial Crosstalk of Bimodal Resistive Sensory Inputs","type":"publication"},{"authors":["Sojiro Sugiura","David Hardman","Thomas George Thuruthel","Yasuhisa Hasegawa","Fumiya Iida"],"categories":null,"content":"","date":1693526400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1693526400,"objectID":"1dbbc54c597573cd7df893c13973d695","permalink":"https://dshardman.github.io/publication/sojiro/","publishdate":"2023-09-01T00:00:00Z","relpermalink":"/publication/sojiro/","section":"publication","summary":"Soft sensing technologies provide a novel alternative for state estimation in wearables and robotic systems. They allow us to capture intrinsic state parameters in a highly conformable manner. However, due to the non-linearities in the materials that make up a soft sensor, it is difficult to develop accurate models of these systems. Consequently, design of these soft sensors is largely user-defined or based on trial and error. Since these sensors conform and take the shape of the sensing body, these issues are further exacerbated when they are installed. This paper presents a framework for the automated design optimization of soft sensors using closed-loop 3D printing of a recyclable hydrogel-based sensing material. Our framework allows direct printing of the sensor on the sensing body using visual feedback, evaluates the sensor performance, and iteratively improves the sensor design. Following preliminary investigations into the material and morphology parameters, this is demonstrated through the optimization of a sensorized glove which can be matched to specific tasks and individual hand shapes. The glove's sensors are tuned to respond only to particular hand poses - including distinguishing between two similar tennis racket grip techniques.","tags":[],"title":"Closed-loop Optimization of Soft Sensor Morphology by Using 3-D Printing of Electrically Conductive Hydrogel","type":"publication"},{"authors":["David Hardman"],"categories":"","content":"In a ceremony on 19th June I was one of twelve recipients of the CSAR 2023 PhD student award, awarded “in recognition of outstanding research and potential with real world application”.\nMy work was selected from more than 160 applications by the Cambridge Society for the Application of Research. More information and the list of 2023 winners can be found on the CSAR website.\n","date":1687651200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1687651200,"objectID":"c53e479afbc73c534f3749f4db737e12","permalink":"https://dshardman.github.io/post/csar/","publishdate":"2023-06-25T00:00:00Z","relpermalink":"/post/csar/","section":"post","summary":"I'm delighted to have been selected as a winner of the 2023 PhD award by the Cambridge Society for the Application of Research.","tags":"","title":"CSAR 2023 Award","type":"post"},{"authors":["David Hardman","Ryman Hashem","Fumiya Iida"],"categories":null,"content":"","date":1684108800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684108800,"objectID":"86a9f99beeb718883bfd452260fbd284","permalink":"https://dshardman.github.io/publication/ringactuator/","publishdate":"2023-05-15T00:00:00Z","relpermalink":"/publication/ringactuator/","section":"publication","summary":"As the task-complexities demanded of soft robots continue to increase, so too does the need for soft sensorized skins which can provide complex tactile feedback. Here we consider the detection of asymmetric deformations by designing and validating an easy-to-fabricate hydrogel-silicone composite sensor for deployment in an underactuated soft robotic manipulator. For proprioception and exteroception, this skin can sense asymmetric bifurcations in a stretchable skin without affecting functionality. Our method facilitates the sensor's use in a wide range of soft robotic actuators - we present its ability to respond to repeated, incremental, and oscillating stimuli in the soft manipulator, and demonstrate its ease of integration into a closed-loop control system. We experimentally find the sensors capable of withstanding over 200\\% strain before the onset of delamination.","tags":[],"title":"Composite Stretchable Sensors for the Detection of Asymmetric Deformations in a Soft Manipulator","type":"publication"},{"authors":["Naoki Tano","Ryman Hashem","David Hardman","Fumiya Iida"],"categories":null,"content":"","date":1684108800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684108800,"objectID":"6d4e18d257edd3ac59f7e98d8eeb74df","permalink":"https://dshardman.github.io/publication/naoki/","publishdate":"2023-05-15T00:00:00Z","relpermalink":"/publication/naoki/","section":"publication","summary":"Sensorized hydrogels are attracting tremendous interest in the manufacture of flexible strain sensors due to their impressive responses and tunable mechanical properties. However, many require extensive fabrication processes and hazardous raw materials, making their practical application difficult. Here, we demonstrate how the parameters of mesoscale cellular mesh sensors can be varied to control and tune the response characteristics of a biocompatible gelatin-based hydrogel using a straightforward fabrication process and readily available low-cost materials. An analytical model is derived to validate the experimental results, providing a framework for design and optimization of sensor morphologies. Using this, 40% changes in gauge factor are demonstrated with no change in material properties, indicating that our in-plane cellular structures are a substantial and feasible method to control the sensitivity of flexible and stretchable strain sensors. We use the structures to demonstrate wearable proprioceptive devices, anisotropic bidirectional responses, and localization of a tactile stimulus.","tags":[],"title":"Variable Response Characteristics of a Soft Sensorized Hydrogel using Mesoscale Cellular Structures","type":"publication"},{"authors":["David Hardman"],"categories":"","content":"During the packed and exciting schedule of the 6th IEEE-RAS International Conference on Soft Robotics (RoboSoft 2023), I was invited to give 2 talks and present one poster (even featuring on the conference’s twitter feed!).\nHats off to you, Hardman! Your presentation on Composite Stretchable Sensors for the Detection of Asymmetric Deformations in a Soft Manipulator was absolutely mind-blowing! #RoboSoft2023 pic.twitter.com/pA5PQShuIZ\n— IEEERoboSoft (@IEEERoboSoft) April 5, 2023 Details of all can be found below.\n“Learning-Based Sensing for Soft Applications.” An invited 20-minute talk in the Modelling Challenges for Soft Robots workshop.\n“Composite Stretchable Sensors for the Detection of Asymmetric Deformations in a Soft Manipulator.” A 15-minute talk accompanying a paper of the same name being published in the conference proceedings.\n“Material-level Sensorization of Hydrogel-based Skins using Data-Driven EIT.” A poster within the Embodied Intelligence and Soft Robotics workshop, alongside a flash talk of its content.\n“Variable Response Characteristics of a Soft Sensorized Hydrogel using Mesoscale Cellular Structures.” A poster of a paper which I co-authored in the conference proceedings, presented by first author Naoki Tano.\n","date":1681516800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681516800,"objectID":"32a103fc0f1ac9dbe511ecfacbebefd5","permalink":"https://dshardman.github.io/post/robosoft23/","publishdate":"2023-04-15T00:00:00Z","relpermalink":"/post/robosoft23/","section":"post","summary":"I had the chance to present my work to an audience of soft roboticists in Singapore during RoboSoft 2023.","tags":"","title":"Talks at RoboSoft","type":"post"},{"authors":["David Hardman","Thomas George Thuruthel","Fumiya Iida"],"categories":null,"content":"","date":1680134400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680134400,"objectID":"af2d0e4c839c357a21c52df6ffaee60a","permalink":"https://dshardman.github.io/publication/eitskin/","publishdate":"2023-03-30T00:00:00Z","relpermalink":"/publication/eitskin/","section":"publication","summary":"A model-free method for the reconstruction of deformations in a hydrogel skin using electrical impedance tomography. The method can be used for damage detection, environmental monitoring, and multi-touch recognition.","tags":[],"title":"Tactile Perception in Hydrogel-based Robotic Skins using Data-Driven Electrical Impedance Tomography","type":"publication"},{"authors":["David Hardman"],"categories":"","content":"From 6-7pm on Tuesday 28th February I’ll be presenting the Bio-Inspired Robotics Lab’s current research at the John Ray Society of St Catherine’s College Cambridge. Talk details can be found below.\nAiming for All-Purpose Robotics\nThough we have seen many robots and machines optimised to perform a specific task or solve a specific problem, the design of multipurpose robots continues to challenge us. In this talk, David Hardman (Cambridge Bio-Inspired Robotics Lab) introduces the key problems, illustrated with practical examples from his work on biomimetic e-skins.\n","date":1676851200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676851200,"objectID":"15ae5fe8e2b3e54109e19784a75e4420","permalink":"https://dshardman.github.io/post/john-ray/","publishdate":"2023-02-20T00:00:00Z","relpermalink":"/post/john-ray/","section":"post","summary":"On Tuesday 28th February I'll be presenting my work in a 1 hour seminar at St Catharine's College.","tags":"","title":"Upcoming Research Talk","type":"post"},{"authors":["Yichen Cai","David Hardman","Fumiya Iida","Thomas George Thuruthel"],"categories":null,"content":"","date":1673913600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673913600,"objectID":"e5bf4e77aec1d890965622b4efac69f8","permalink":"https://dshardman.github.io/publication/yichen/","publishdate":"2023-01-17T00:00:00Z","relpermalink":"/publication/yichen/","section":"publication","summary":"As soft robotic systems become increasingly complex, there is a need to develop sensory systems which can provide rich state information to the robot for feedback control. Multi-axis force sensing and control is one of the less explored problems in this domain. There are numerous challenges in the development of a multi-axis soft sensor - from the design and fabrication to the data processing and modelling. This work presents the design and development of a novel multi-axis soft sensor using a gelatin-based ionic hydrogel and 3D printing technology. A learning-based modelling approach coupled with sensor redundancy is developed to model the environmentally dependent soft sensors. Numerous real-time experiments are conducted to test the performance of the sensor and its applicability in closed-loop control tasks. Our results indicate that the soft sensor can predict force values and orientation angle within 4% and 7% of their total range, respectively.","tags":[],"title":"Design and Development of a Hydrogel-based Soft Sensor for Multi-Axis Force Control","type":"publication"},{"authors":["Seppe Terryn","David Hardman","Thomas George Thuruthel","Ellen Roels","Fatemeh Sahraeeazartamar","Fumiya Iida"],"categories":null,"content":"","date":1667174400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667174400,"objectID":"91eb151558057bf789a1da3799f9cce2","permalink":"https://dshardman.github.io/publication/healingrecovery/","publishdate":"2022-10-31T00:00:00Z","relpermalink":"/publication/healingrecovery/","section":"publication","summary":"Comparing recalibration methods for a sensorised skin which has damaged and healed in multiple locations, affecting the response of the sensor channels. Transfer learning is used to recover the tactile sensitivity as quickly as possible.","tags":[],"title":"Learning-Based Damage Recovery for Healable Soft Electronic Skins","type":"publication"},{"authors":["David Hardman","Thomas George Thuruthel","Antonia Georgopoulou","Frank Clemens","Fumiya Iida"],"categories":null,"content":"","date":1663372800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663372800,"objectID":"ef953b1ee3f7881b1b0f6b60c50d1830","permalink":"https://dshardman.github.io/publication/micromachines/","publishdate":"2022-09-17T00:00:00Z","relpermalink":"/publication/micromachines/","section":"publication","summary":"The human tactile system is composed of multi-functional mechanoreceptors distributed in an optimized manner. Having the ability to design and optimize multi-modal soft sensory systems can further enhance the capabilities of current soft robotic systems. This work presents a complete framework for the fabrication of soft sensory fiber networks for contact localization, using pellet-based 3D printing of piezoresistive elastomers to manufacture flexible sensory networks with precise and repeatable performances. Given a desirable soft sensor property, our methodology can design and fabricate optimized sensor morphologies without human intervention. Extensive simulation and experimental studies are performed on two printed networks, comparing a baseline network to one optimized via an existing information theory based approach. Machine learning is used for contact localization based on the sensor responses. The sensor responses match simulations with tunable performances and good localization accuracy, even in the presence of damage and nonlinear material properties. The potential of the networks to function as capacitive sensors is also demonstrated.","tags":[],"title":"3D Printable Soft Sensory Fiber Networks for Robust and Complex Tactile Sensing","type":"publication"},{"authors":["David Hardman"],"categories":"","content":"Episode 17 of UK-RAS’s Robot Talk podcast has just been released, in which I talk with Dr Claire Asher about the pros and cons of integrating our sensorised hydrogel skins into bio-inspired robots. The episode also features the fascinating work of Valentina Lo Gatto and Adrian Thomas.\nListen here.\n“Bioinspired Robots: learning from nature: In many areas of robotics, scientists and engineers are taking inspiration from nature in their designs. Bioinspired robotics now encompasses a huge number of different research fields and applications that we’ve discussed before, from sensing to locomotion and from medical to agricultural robotics. This month, I’m chatting to three roboticists who’ve taken a leaf out of nature’s book to develop innovative new robots.\nValentina Lo Gatto is a PhD student in Robotics and Autonomous Systems at the Bristol Robotics Lab, where she is part of the SoftLab and the Morphological Computation Group. The main goal of her research at BRL is to investigate the application of the concepts of Bioinspiration, Soft Robotics and Morphological Computation to space probes design, specifically probes that will need to be able to autonomously explore delicate marine environments such those hidden under the icy surfaces of some of the moons of the outer solar system (e.g., Europa, Enceladus, Ganymede).\nDavid Hardman is a PhD student in the Bio-Inspired Robotics Lab at the University of Cambridge, where he works on the design and development of soft, flexible sensors and sensing materials. After receiving his MEng in mechanical and materials engineering from Cambridge in 2020, he began focussing on including stretchy, bendy, and compliant sensors into robotic systems, where they function as artificial skins which conform to and sense a robot’s surroundings.\nAdrian Thomas is Professor of Biomechanics in the Zoology Department, Oxford University. He founded the Oxford Animal Flight Group in 1996, and led that group until 2015 when he founded his Oxford Spinout company Animal Dynamics. Animal Dynamics works on bio inspired autonomous vehicles and systems, mainly cargo delivery in air or underwater. Animal Dynamics has raised over £20 million from venture capital. Its main product is a large cargo delivery drone ‘Stork’ capable of carrying 135kg over 400km.”\n","date":1655078400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655078400,"objectID":"1c13e0e5d19df9f3f6c46ce5c387ce2c","permalink":"https://dshardman.github.io/post/robot-talk/","publishdate":"2022-06-13T00:00:00Z","relpermalink":"/post/robot-talk/","section":"post","summary":"I talk to Dr Claire Asher in the latest episode Bioinspired Robots: learning from nature.","tags":"","title":"Robot Talk podcast appearance","type":"post"},{"authors":["David Hardman"],"categories":"","content":"My new paper “Self-healing ionic gelatin/glycerol hydrogels for strain sensing applications” is featured on Cambridge University’s research news following its publication in NPG Asia Materials.\nThis work looks at the development, characterisation, and applications of a healable gelatin-based sensor for soft robotics. As seen in the University’s promotional video below, it is easy to 3D print or cast into different shapes.\nRead more here.\n","date":1645142400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645142400,"objectID":"f10429b68837ed207b1bfb333305f2a1","permalink":"https://dshardman.github.io/post/jelly-press/","publishdate":"2022-02-18T00:00:00Z","relpermalink":"/post/jelly-press/","section":"post","summary":"My recent paper \"Self-healing ionic gelatin/glycerol hydrogels for strain sensing applications\" is promoted by Cambridge University after its publication in NPG Asia Materials.","tags":"","title":"Research features on Cambridge University's news website","type":"post"},{"authors":["David Hardman","Thomas George Thuruthel","Fumiya Iida"],"categories":null,"content":"","date":1645142400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645142400,"objectID":"147b951c8c109d9f04c216fbe334ca01","permalink":"https://dshardman.github.io/publication/npghydrogel/","publishdate":"2022-02-18T00:00:00Z","relpermalink":"/publication/npghydrogel/","section":"publication","summary":"Development, characterisation, and applications of a healable gelatin-based sensor for soft robotics.","tags":[],"title":"Self-healing ionic gelatin/glycerol hydrogels for strain sensing applications","type":"publication"},{"authors":["David Hardman"],"categories":"","content":"My recent publication in Scientific Reports - “Manipulation of Free-Floating Objects using Faraday Flows and Deep Reinforcement Learning” - has just been featured on Cambridge University Engineering Department’s website.\nHere I looked at how we can control the motion of an object floating on the surface of water without touching it - instead just vibrating the water to produce waves at a fixed point nearby. Given the difficulty of modelling this problem, we used deep reinforcement learning trained with real-world data to develop the controller.\nRead more here, or see the video below.\n","date":1643328000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643328000,"objectID":"fdce7bd311d926c8b5de48408dcad4b7","permalink":"https://dshardman.github.io/post/water-press/","publishdate":"2022-01-28T00:00:00Z","relpermalink":"/post/water-press/","section":"post","summary":"My recent paper \"Manipulation of Free-Floating Objects using Faraday Flows and Deep Reinforcement Learning\" has been featured on Cambridge University Engineering Department's website.","tags":"","title":"Research features on department's website","type":"post"},{"authors":["David Hardman","Thomas George Thuruthel","Fumiya Iida"],"categories":null,"content":"","date":1641772800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641772800,"objectID":"946043fda4c023f62b843aebd2d74585","permalink":"https://dshardman.github.io/publication/scientificreports/","publishdate":"2022-01-10T00:00:00Z","relpermalink":"/publication/scientificreports/","section":"publication","summary":"The ability to remotely control a free-floating object through surface flows on a fluid medium can facilitate numerous applications. Current studies on this problem have been limited to uni-directional motion control due to the challenging nature of the control problem. Analytical modelling of the object dynamics is difficult due to the high-dimensionality and mixing of the surface flows while the control problem is hard due to the nonlinear slow dynamics of the fluid medium, underactuation, and chaotic regions. This study presents a methodology for manipulation of free-floating objects using large-scale physical experimentation and recent advances in deep reinforcement learning. We demonstrate our methodology through the open-loop control of a free-floating object in water using a robotic arm. Our learned control policy is relatively quick to obtain, highly data efficient, and easily scalable to a higher-dimensional parameter space and/or experimental scenarios. Our results show the potential of data-driven approaches for solving and analyzing highly complex nonlinear control problems.","tags":[],"title":"Manipulation of free-floating objects using Faraday flows and deep reinforcement learning","type":"publication"},{"authors":["David Hardman"],"categories":"","content":"June 2022 update: We’ll be taking part in this event again this year - see the trailer here.\nOn Wednesday 23rd June 4pm-6pm BST, I’ll be hosting the Bio-Inspired Robotics Lab’s livestreamed demos as part of Robot Lab Live.\nWe’ll be exploring how robots can be taught to help doctors examine patients, and how a robotic chef can use taste sensors to improve its scrambled eggs. After presenting our research we’ll be asking the live audience: “Would you eat breakfast that’s been cooked by a robot?”\n","date":1622505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622505600,"objectID":"743b3dade39b362b16dd626d5c7cc619","permalink":"https://dshardman.github.io/post/robot-lab-live/","publishdate":"2021-06-01T00:00:00Z","relpermalink":"/post/robot-lab-live/","section":"post","summary":"I'll be hosting the lab's livestreamed demos at EPSRC UK-Robotics and Autonomous Systems (UK-RAS) Network's flagship event.","tags":"","title":"BIRL joins Robot Lab Live","type":"post"},{"authors":["David Hardman","Josie Hughes","Thomas George Thuruthel","Kieran Gilday","Fumiya Iida"],"categories":null,"content":"","date":1618704000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618704000,"objectID":"5b6f886a238d28ee0c42ae96847add3e","permalink":"https://dshardman.github.io/publication/ral-hydrogel/","publishdate":"2021-04-18T00:00:00Z","relpermalink":"/publication/ral-hydrogel/","section":"publication","summary":"The ability to 3D print soft materials with integrated strain sensors enables significant flexibility for the design and fabrication of soft robots. Hydrogels provide an interesting alternative to traditional soft robot materials, allowing for more varied fabrication techniques. In this work, we investigate the 3D printing of a gelatin-glycerol hydrogel, where transglutaminase is used to catalyse the crosslinking of the hydrogel such that its material properties can be controlled for 3D printing. By including electron-conductive elements (aqueous carbon black) in the hydrogel we can create highly flexible and linear soft strain sensors. We present a first investigation into adapting a desktop 3D printer and optimizing its control parameters to fabricate sensorized 2D and 3D structures which can undergo \u003e300% strain and show a response to strain which is highly linear and synchronous. To demonstrate the capabilities of this material and fabrication approach, we produce some example 2D and 3D structres and show their sensing capabilities.","tags":[],"title":"3D Printable Sensorized Soft Gelatin Hydrogel for Multi-Material Soft Structures","type":"publication"},{"authors":["David Hardman","Thomas George Thuruthel","Fumiya Iida"],"categories":null,"content":"","date":1606953600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606953600,"objectID":"7d23d6f02d1e4daec1b314b8c53cf0c0","permalink":"https://dshardman.github.io/publication/taros/","publishdate":"2020-12-03T00:00:00Z","relpermalink":"/publication/taros/","section":"publication","summary":"Control of robots has largely been based on the assumption of a fixed morphology. Accordingly, robot designs have been stationary in time, except for the case of modular robots. Any drastic change in morphology, hence, requires a remodelling of the controller. This work takes inspiration from developmental robotics to present a piecewise morphology-controller growth/adaptation strategy that facilitates fast and reliable control adaptation to growing robots. We demonstrate our methodology on a simple 3 degree of freedom walking robot with adjustable foot lengths and with varying inertial conditions. Our results show not only the effectiveness and reliability of the piecewise morphology controller co-adaptation (PMCCA) strategy, but also highlight the need for morphological adaptation as a robot design strategy.","tags":[],"title":"Towards Growing Robots - A Piecewise Morphology-Controller Co-adaptation Strategy for Legged Locomotion","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://dshardman.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"https://dshardman.github.io/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"}]