<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | David Hardman</title>
    <link>https://dshardman.github.io/post/</link>
      <atom:link href="https://dshardman.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 25 Jun 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://dshardman.github.io/media/icon_hu9d558420c7118401edbc78d30d177da6_214587_512x512_fill_lanczos_center_3.png</url>
      <title>Posts</title>
      <link>https://dshardman.github.io/post/</link>
    </image>
    
    <item>
      <title>CSAR 2023 Award</title>
      <link>https://dshardman.github.io/post/csar/</link>
      <pubDate>Sun, 25 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/post/csar/</guid>
      <description>&lt;p&gt;In a ceremony on 19th June I was one of twelve recipients of the CSAR 2023 PhD student award, awarded &lt;em&gt;&amp;ldquo;in recognition of outstanding research and potential with real world application&amp;rdquo;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;My work was selected from more than 160 applications by the Cambridge Society for the Application of Research. More information and the list of 2023 winners can be found &lt;a href=&#34;https://www.csar.org.uk/student-awards/2023/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;on the CSAR website&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Talks at RoboSoft</title>
      <link>https://dshardman.github.io/post/robosoft23/</link>
      <pubDate>Sat, 15 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/post/robosoft23/</guid>
      <description>&lt;p&gt;During the packed and exciting schedule of the 6th IEEE-RAS International Conference on Soft Robotics (RoboSoft 2023), I was invited to give 2 talks and present one poster (even featuring on the conference&amp;rsquo;s twitter feed!).&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Hats off to you, Hardman! Your presentation on Composite Stretchable Sensors for the Detection of Asymmetric Deformations in a Soft Manipulator was absolutely mind-blowing! &lt;a href=&#34;https://twitter.com/hashtag/RoboSoft2023?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#RoboSoft2023&lt;/a&gt; &lt;a href=&#34;https://t.co/pA5PQShuIZ&#34;&gt;pic.twitter.com/pA5PQShuIZ&lt;/a&gt;&lt;/p&gt;&amp;mdash; IEEERoboSoft (@IEEERoboSoft) &lt;a href=&#34;https://twitter.com/IEEERoboSoft/status/1643460895367110656?ref_src=twsrc%5Etfw&#34;&gt;April 5, 2023&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;Details of all can be found below.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&amp;ldquo;Learning-Based Sensing for Soft Applications.&amp;rdquo;&lt;/strong&gt; An invited 20-minute talk in the &lt;em&gt;Modelling Challenges for Soft Robots&lt;/em&gt; workshop.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&amp;ldquo;Composite Stretchable Sensors for the Detection of Asymmetric Deformations in a Soft Manipulator.&amp;rdquo;&lt;/strong&gt; A 15-minute talk accompanying a paper of the same name being published in the conference proceedings.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&amp;ldquo;Material-level Sensorization of Hydrogel-based Skins using Data-Driven EIT.&amp;rdquo;&lt;/strong&gt; A poster within the &lt;em&gt;Embodied Intelligence and Soft Robotics&lt;/em&gt; workshop, alongside a flash talk of its content.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&amp;ldquo;Variable Response Characteristics of a Soft Sensorized Hydrogel using
Mesoscale Cellular Structures.&amp;rdquo;&lt;/strong&gt; A poster of a paper which I co-authored in the conference proceedings, presented by first author Naoki Tano.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Upcoming Research Talk</title>
      <link>https://dshardman.github.io/post/john-ray/</link>
      <pubDate>Mon, 20 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/post/john-ray/</guid>
      <description>&lt;p&gt;From 6-7pm on Tuesday 28th February I&amp;rsquo;ll be presenting the Bio-Inspired Robotics Lab&amp;rsquo;s current research at the &lt;a href=&#34;https://www.johnray.caths.cam.ac.uk/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;John Ray Society&lt;/a&gt; of St Catherine&amp;rsquo;s College Cambridge. Talk details can be found below.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Aiming for All-Purpose Robotics&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Though we have seen many robots and machines optimised to perform a specific task or solve a specific problem, the design of multipurpose robots continues to challenge us. In this talk, David Hardman (Cambridge Bio-Inspired Robotics Lab) introduces the key problems, illustrated with practical examples from his work on biomimetic e-skins.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Robot Talk podcast appearance</title>
      <link>https://dshardman.github.io/post/robot-talk/</link>
      <pubDate>Mon, 13 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/post/robot-talk/</guid>
      <description>&lt;p&gt;Episode 17 of UK-RAS&amp;rsquo;s &lt;em&gt;Robot Talk&lt;/em&gt; podcast has just been released, in which I talk with Dr Claire Asher about the pros and cons of integrating our sensorised hydrogel skins into bio-inspired robots. The episode also features the fascinating work of Valentina Lo Gatto and Adrian Thomas.&lt;/p&gt;
&lt;p&gt;Listen &lt;a href=&#34;https://ukrobotics.libsyn.com/episode-seventeen-bioinspired-robots-learning-from-nature&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&amp;ldquo;&lt;strong&gt;Bioinspired Robots: learning from nature:&lt;/strong&gt;
&lt;em&gt;In many areas of robotics, scientists and engineers are taking inspiration from nature in their designs. Bioinspired robotics now encompasses a huge number of different research fields and applications that we’ve discussed before, from sensing to locomotion and from medical to agricultural robotics. This month, I’m chatting to three roboticists who’ve taken a leaf out of nature’s book to develop innovative new robots.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Valentina Lo Gatto is a PhD student in Robotics and Autonomous Systems at the Bristol Robotics Lab, where she is part of the SoftLab and the Morphological Computation Group. The main goal of her research at BRL is to investigate the application of the concepts of Bioinspiration, Soft Robotics and Morphological Computation to space probes design, specifically probes that will need to be able to autonomously explore delicate marine environments such those hidden under the icy surfaces of some of the moons of the outer solar system (e.g., Europa, Enceladus, Ganymede).&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;David Hardman is a PhD student in the Bio-Inspired Robotics Lab at the University of Cambridge, where he works on the design and development of soft, flexible sensors and sensing materials. After receiving his MEng in mechanical and materials engineering from Cambridge in 2020, he began focussing on including stretchy, bendy, and compliant sensors into robotic systems, where they function as artificial skins which conform to and sense a robot’s surroundings.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Adrian Thomas is Professor of Biomechanics in the Zoology Department, Oxford University. He founded the Oxford Animal Flight Group in 1996, and led that group until 2015 when he founded his Oxford Spinout company Animal Dynamics. Animal Dynamics works on bio inspired autonomous vehicles and systems, mainly cargo delivery in air or underwater. Animal Dynamics has raised over £20 million from venture capital. Its main product is a large cargo delivery drone &amp;lsquo;Stork&amp;rsquo; capable of carrying 135kg over 400km.&amp;rdquo;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Research features on Cambridge University&#39;s news website</title>
      <link>https://dshardman.github.io/post/jelly-press/</link>
      <pubDate>Fri, 18 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/post/jelly-press/</guid>
      <description>&lt;p&gt;My new paper &amp;ldquo;Self-healing ionic gelatin/glycerol hydrogels for strain sensing applications&amp;rdquo; is featured on Cambridge University&amp;rsquo;s research news following its publication in &lt;em&gt;NPG Asia Materials&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;This work looks at the development, characterisation, and applications of a healable gelatin-based sensor for soft robotics. As seen in the University&amp;rsquo;s promotional video below, it is easy to 3D print or cast into different shapes.&lt;/p&gt;
&lt;p&gt;Read more &lt;a href=&#34;https://www.cam.ac.uk/research/news/self-healing-materials-for-robotics-made-from-jelly-and-salt&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;iframe
    width=&#34;640&#34;
    height=&#34;480&#34;
    src=&#34;https://www.youtube.com/embed/eVH0YCeI464&#34;
    frameborder=&#34;0&#34;
    allow=&#34;autoplay; encrypted-media&#34;
    allowfullscreen
&gt;
&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>Research features on department&#39;s website</title>
      <link>https://dshardman.github.io/post/water-press/</link>
      <pubDate>Fri, 28 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/post/water-press/</guid>
      <description>&lt;p&gt;My recent publication in &lt;em&gt;Scientific Reports&lt;/em&gt; - &amp;ldquo;Manipulation of Free-Floating Objects using Faraday Flows and Deep Reinforcement Learning&amp;rdquo; - has just been featured on Cambridge University Engineering Department&amp;rsquo;s website.&lt;/p&gt;
&lt;p&gt;Here I looked at how we can control the motion of an object floating on the surface of water &lt;em&gt;without touching it&lt;/em&gt; - instead just vibrating the water to produce waves at a fixed point nearby. Given the difficulty of modelling this problem, we used deep reinforcement learning trained with real-world data to develop the controller.&lt;/p&gt;
&lt;p&gt;Read more &lt;a href=&#34;http://www.eng.cam.ac.uk/news/remote-control-floating-objects-solving-complex-fluid-dynamics-problem-ai&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;, or see the video below.&lt;/p&gt;
&lt;iframe
    width=&#34;640&#34;
    height=&#34;480&#34;
    src=&#34;https://www.youtube.com/embed/2FzWJyX9ieU&#34;
    frameborder=&#34;0&#34;
    allow=&#34;autoplay; encrypted-media&#34;
    allowfullscreen
&gt;
&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>BIRL joins Robot Lab Live</title>
      <link>https://dshardman.github.io/post/robot-lab-live/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://dshardman.github.io/post/robot-lab-live/</guid>
      <description>&lt;p&gt;&lt;strong&gt;June 2022 update:&lt;/strong&gt; &lt;em&gt;We&amp;rsquo;ll be taking part in this event again this year - see the trailer &lt;a href=&#34;https://www.youtube.com/watch?v=nL2uH8tEKxY&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;On Wednesday 23rd June 4pm-6pm BST, I&amp;rsquo;ll be hosting the Bio-Inspired Robotics Lab&amp;rsquo;s livestreamed demos as part of &lt;a href=&#34;https://www.ukras.org.uk/robotics-week/robot-lab-live/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Robot Lab Live&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ll be exploring how robots can be taught to help doctors examine patients, and how a robotic chef can use taste sensors to improve its scrambled eggs. After presenting our research we&amp;rsquo;ll be asking the live audience: &lt;em&gt;&amp;ldquo;Would you eat breakfast that&amp;rsquo;s been cooked by a robot?&amp;rdquo;&lt;/em&gt;&lt;/p&gt;
&lt;iframe
    width=&#34;640&#34;
    height=&#34;480&#34;
    src=&#34;https://www.youtube.com/embed/MwhnJaQqEz4&#34;
    frameborder=&#34;0&#34;
    allow=&#34;autoplay; encrypted-media&#34;
    allowfullscreen
&gt;
&lt;/iframe&gt;
</description>
    </item>
    
  </channel>
</rss>
